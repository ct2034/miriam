{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Rolling Regression\n",
      "Author: Thomas Wiecki\n",
      "\n",
      "* [Pairs trading](https://www.quantopian.com/posts/pairs-trading-algorithm-1) is a famous technique in algorithmic trading that plays two stocks against each other.\n",
      "* For this to work, stocks must be correlated (cointegrated).\n",
      "* One common example is the price of gold (GLD) and the price of gold mining operations (GDX)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import pandas as pd\n",
      "from pandas_datareader import data\n",
      "import numpy as np\n",
      "import pymc3 as pm\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lets load the prices of GDX and GLD."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prices = data.YahooDailyReader(symbols=['GLD', 'GDX'], end='2014-8-1').read().loc['Adj Close', :, :].iloc[:1000]\n",
      "prices.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Plotting the prices over time suggests a strong correlation. However, the correlation seems to change over time."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure(figsize=(9, 6))\n",
      "ax = fig.add_subplot(111, xlabel='Price GDX in \\$', ylabel='Price GLD in \\$')\n",
      "colors = np.linspace(0.1, 1, len(prices))\n",
      "mymap = plt.get_cmap(\"winter\")\n",
      "sc = ax.scatter(prices.GDX, prices.GLD, c=colors, cmap=mymap, lw=0)\n",
      "cb = plt.colorbar(sc)\n",
      "cb.ax.set_yticklabels([str(p.date()) for p in prices[::len(prices)//10].index]);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A naive approach would be to estimate a linear model and ignore the time domain."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with pm.Model() as model_reg:\n",
      "    pm.glm.glm('GLD ~ GDX', prices)\n",
      "    trace_reg = pm.sample(2000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The posterior predictive plot shows how bad the fit is."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure(figsize=(9, 6))\n",
      "ax = fig.add_subplot(111, xlabel='Price GDX in \\$', ylabel='Price GLD in \\$', \n",
      "            title='Posterior predictive regression lines')\n",
      "sc = ax.scatter(prices.GDX, prices.GLD, c=colors, cmap=mymap, lw=0)\n",
      "pm.glm.plot_posterior_predictive(trace_reg[100:], samples=100, \n",
      "                              label='posterior predictive regression lines',\n",
      "                              lm=lambda x, sample: sample['Intercept'] + sample['GDX'] * x,\n",
      "                              eval=np.linspace(prices.GDX.min(), prices.GDX.max(), 100))\n",
      "cb = plt.colorbar(sc)\n",
      "cb.ax.set_yticklabels([str(p.date()) for p in prices[::len(prices)//10].index]);\n",
      "ax.legend(loc=0);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Rolling regression\n",
      "\n",
      "Next, we will build an improved model that will allow for changes in the regression coefficients over time. Specifically, we will assume that intercept and slope follow a random-walk through time. That idea is similar to the [stochastic volatility model](http://pymc-devs.github.io/pymc3/stochastic_volatility/).\n",
      "\n",
      "$$ \\alpha_t \\sim \\mathcal{N}(\\alpha_{t-1}, \\sigma_\\alpha^2) $$\n",
      "$$ \\beta_t \\sim \\mathcal{N}(\\beta_{t-1}, \\sigma_\\beta^2) $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, lets define the hyper-priors for $\\sigma_\\alpha^2$ and $\\sigma_\\beta^2$. This parameter can be interpreted as the volatility in the regression coefficients."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model_randomwalk = pm.Model()\n",
      "with model_randomwalk:\n",
      "    # std of random walk, best sampled in log space.\n",
      "    sigma_alpha = pm.Exponential('sigma_alpha', 1./.02, testval = .1)\n",
      "    sigma_beta = pm.Exponential('sigma_beta', 1./.02, testval = .1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, we define the regression parameters that are not a single random variable but rather a random vector with the above stated dependence structure. So as not to fit a coefficient to a single data point, we will chunk the data into bins of 50 and apply the same coefficients to all data points in a single bin."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import theano.tensor as T\n",
      "\n",
      "# To make the model simpler, we will apply the same coefficient for 50 data points at a time\n",
      "subsample_alpha = 50\n",
      "subsample_beta = 50\n",
      "with model_randomwalk:\n",
      "    alpha = pm.GaussianRandomWalk('alpha', sigma_alpha**-2, \n",
      "                                  shape=len(prices) // subsample_alpha)\n",
      "    beta = pm.GaussianRandomWalk('beta', sigma_beta**-2, \n",
      "                                 shape=len(prices) // subsample_beta)\n",
      "    \n",
      "    # Make coefficients have the same length as prices\n",
      "    alpha_r = T.repeat(alpha, subsample_alpha)\n",
      "    beta_r = T.repeat(beta, subsample_beta)    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Perform the regression given coefficients and data and link to the data via the likelihood."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with model_randomwalk:\n",
      "    # Define regression\n",
      "    regression = alpha_r + beta_r * prices.GDX.values\n",
      "    \n",
      "    # Assume prices are Normally distributed, the mean comes from the regression.\n",
      "    sd = pm.Uniform('sd', 0, 20)\n",
      "    likelihood = pm.Normal('y', \n",
      "                           mu=regression, \n",
      "                           sd=sd, \n",
      "                           observed=prices.GLD.values)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Inference. Despite this being quite a complex model, NUTS handles it wells."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy import optimize\n",
      "with model_randomwalk:\n",
      "    # First optimize random walk\n",
      "    start = pm.find_MAP(vars=[alpha, beta], fmin=optimize.fmin_l_bfgs_b)\n",
      "    \n",
      "    # Sample\n",
      "    step = pm.NUTS(scaling=start)\n",
      "    trace_rw = pm.sample(2000, step, start=start)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Analysis of results"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$\\alpha$, the intercept, does not seem to change over time."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure(figsize=(8, 6))\n",
      "ax = plt.subplot(111, xlabel='time', ylabel='alpha', title='Change of alpha over time.')\n",
      "ax.plot(trace_rw[-1000:][alpha].T, 'r', alpha=.05);\n",
      "ax.set_xticklabels([str(p.date()) for p in prices[::len(prices)//5].index]);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However, the slope does."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure(figsize=(8, 6))\n",
      "ax = fig.add_subplot(111, xlabel='time', ylabel='beta', title='Change of beta over time')\n",
      "ax.plot(trace_rw[-1000:][beta].T, 'b', alpha=.05);\n",
      "ax.set_xticklabels([str(p.date()) for p in prices[::len(prices)//5].index]);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The posterior predictive plot shows that we capture the change in regression over time much better. Note that we should have used returns instead of prices. The model would still work the same, but the visualisations would not be quite as clear."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure(figsize=(8, 6))\n",
      "ax = fig.add_subplot(111, xlabel='Price GDX in \\$', ylabel='Price GLD in \\$', \n",
      "            title='Posterior predictive regression lines')\n",
      "\n",
      "colors = np.linspace(0.1, 1, len(prices))\n",
      "colors_sc = np.linspace(0.1, 1, len(trace_rw[-500::10]['alpha'].T))\n",
      "mymap = plt.get_cmap('winter')\n",
      "mymap_sc = plt.get_cmap('winter')\n",
      "\n",
      "xi = np.linspace(prices.GDX.min(), prices.GDX.max(), 50)\n",
      "for i, (alpha, beta) in enumerate(zip(trace_rw[-500::10]['alpha'].T, trace_rw[-500::10]['beta'].T)):\n",
      "    for a, b in zip(alpha, beta):\n",
      "        ax.plot(xi, a + b*xi, alpha=.05, lw=1, c=mymap_sc(colors_sc[i]))\n",
      "        \n",
      "sc = ax.scatter(prices.GDX, prices.GLD, label='data', cmap=mymap, c=colors)\n",
      "cb = plt.colorbar(sc)\n",
      "cb.ax.set_yticklabels([str(p.date()) for p in prices[::len(prices)//10].index]);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    }
   ],
   "metadata": {}
  }
 ]
}